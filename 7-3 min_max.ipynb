{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0) \n",
    "    \n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    print(numerator, denominator)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "# 아주 작은 수를 더해줘서 0이 되지 않게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array(\n",
    "    [\n",
    "        [1, 2, 30, 4, 5],\n",
    "        [2, 3, 40, 5, 6],\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2, 30,  4,  5],\n",
       "       [ 2,  3, 40,  5,  6]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  480.6762 \n",
      "Pred: \n",
      " [[23.801462]\n",
      " [30.654764]]\n",
      "1 Cost:  266.0338 \n",
      "Pred: \n",
      " [[19.037893]\n",
      " [24.303146]]\n",
      "2 Cost:  147.24461 \n",
      "Pred: \n",
      " [[15.494144]\n",
      " [19.578003]]\n",
      "3 Cost:  81.50325 \n",
      "Pred: \n",
      " [[12.857847]\n",
      " [16.06284 ]]\n",
      "4 Cost:  45.120064 \n",
      "Pred: \n",
      " [[10.896631]\n",
      " [13.447809]]\n",
      "5 Cost:  24.984566 \n",
      "Pred: \n",
      " [[ 9.437627]\n",
      " [11.502418]]\n",
      "6 Cost:  13.841 \n",
      "Pred: \n",
      " [[ 8.35223 ]\n",
      " [10.055188]]\n",
      "7 Cost:  7.6738253 \n",
      "Pred: \n",
      " [[7.5447726]\n",
      " [8.978554 ]]\n",
      "8 Cost:  4.2607284 \n",
      "Pred: \n",
      " [[6.9440794]\n",
      " [8.177616 ]]\n",
      "9 Cost:  2.3718233 \n",
      "Pred: \n",
      " [[6.4972067]\n",
      " [7.581777 ]]\n",
      "10 Cost:  1.326448 \n",
      "Pred: \n",
      " [[6.164764]\n",
      " [7.138517]]\n",
      "11 Cost:  0.74790585 \n",
      "Pred: \n",
      " [[5.9174485]\n",
      " [6.8087645]]\n",
      "12 Cost:  0.42772323 \n",
      "Pred: \n",
      " [[5.7334623]\n",
      " [6.563453 ]]\n",
      "13 Cost:  0.25052506 \n",
      "Pred: \n",
      " [[5.596589 ]\n",
      " [6.3809614]]\n",
      "14 Cost:  0.15245707 \n",
      "Pred: \n",
      " [[5.4947634]\n",
      " [6.2452006]]\n",
      "15 Cost:  0.098182775 \n",
      "Pred: \n",
      " [[5.419011 ]\n",
      " [6.1442056]]\n",
      "16 Cost:  0.06814483 \n",
      "Pred: \n",
      " [[5.3626547]\n",
      " [6.069074 ]]\n",
      "17 Cost:  0.051520366 \n",
      "Pred: \n",
      " [[5.320729 ]\n",
      " [6.0131826]]\n",
      "18 Cost:  0.04231912 \n",
      "Pred: \n",
      " [[5.2895374]\n",
      " [5.9716043]]\n",
      "19 Cost:  0.0372263 \n",
      "Pred: \n",
      " [[5.2663326]\n",
      " [5.9406743]]\n",
      "20 Cost:  0.03440679 \n",
      "Pred: \n",
      " [[5.2490673]\n",
      " [5.917665 ]]\n",
      "21 Cost:  0.032845642 \n",
      "Pred: \n",
      " [[5.2362223]\n",
      " [5.90055  ]]\n",
      "22 Cost:  0.03198088 \n",
      "Pred: \n",
      " [[5.2266645]\n",
      " [5.8878174]]\n",
      "23 Cost:  0.031501643 \n",
      "Pred: \n",
      " [[5.219554 ]\n",
      " [5.8783474]]\n",
      "24 Cost:  0.031235656 \n",
      "Pred: \n",
      " [[5.2142625]\n",
      " [5.871303 ]]\n",
      "25 Cost:  0.031087633 \n",
      "Pred: \n",
      " [[5.2103243]\n",
      " [5.8660636]]\n",
      "26 Cost:  0.031004881 \n",
      "Pred: \n",
      " [[5.207393 ]\n",
      " [5.8621674]]\n",
      "27 Cost:  0.0309583 \n",
      "Pred: \n",
      " [[5.2052107]\n",
      " [5.859269 ]]\n",
      "28 Cost:  0.03093177 \n",
      "Pred: \n",
      " [[5.2035866]\n",
      " [5.8571153]]\n",
      "29 Cost:  0.030916397 \n",
      "Pred: \n",
      " [[5.2023764]\n",
      " [5.8555126]]\n",
      "30 Cost:  0.030907094 \n",
      "Pred: \n",
      " [[5.201475 ]\n",
      " [5.8543224]]\n",
      "31 Cost:  0.030901082 \n",
      "Pred: \n",
      " [[5.2008023]\n",
      " [5.8534374]]\n",
      "32 Cost:  0.030897025 \n",
      "Pred: \n",
      " [[5.200301]\n",
      " [5.852781]]\n",
      "33 Cost:  0.030893955 \n",
      "Pred: \n",
      " [[5.1999264]\n",
      " [5.852293 ]]\n",
      "34 Cost:  0.030891556 \n",
      "Pred: \n",
      " [[5.1996465]\n",
      " [5.851931 ]]\n",
      "35 Cost:  0.030889478 \n",
      "Pred: \n",
      " [[5.1994367]\n",
      " [5.8516626]]\n",
      "36 Cost:  0.03088748 \n",
      "Pred: \n",
      " [[5.1992793]\n",
      " [5.8514647]]\n",
      "37 Cost:  0.030885724 \n",
      "Pred: \n",
      " [[5.1991606]\n",
      " [5.8513174]]\n",
      "38 Cost:  0.030883905 \n",
      "Pred: \n",
      " [[5.199071 ]\n",
      " [5.8512096]]\n",
      "39 Cost:  0.030882113 \n",
      "Pred: \n",
      " [[5.1990027]\n",
      " [5.8511305]]\n",
      "40 Cost:  0.030880455 \n",
      "Pred: \n",
      " [[5.1989512]\n",
      " [5.851073 ]]\n",
      "41 Cost:  0.03087857 \n",
      "Pred: \n",
      " [[5.1989107]\n",
      " [5.8510313]]\n",
      "42 Cost:  0.03087686 \n",
      "Pred: \n",
      " [[5.1988792]\n",
      " [5.851001 ]]\n",
      "43 Cost:  0.030875055 \n",
      "Pred: \n",
      " [[5.1988544]\n",
      " [5.85098  ]]\n",
      "44 Cost:  0.030873371 \n",
      "Pred: \n",
      " [[5.198835]\n",
      " [5.850965]]\n",
      "45 Cost:  0.030871734 \n",
      "Pred: \n",
      " [[5.198819]\n",
      " [5.850955]]\n",
      "46 Cost:  0.030870076 \n",
      "Pred: \n",
      " [[5.198806 ]\n",
      " [5.8509483]]\n",
      "47 Cost:  0.030868273 \n",
      "Pred: \n",
      " [[5.198794 ]\n",
      " [5.8509445]]\n",
      "48 Cost:  0.030866496 \n",
      "Pred: \n",
      " [[5.198784]\n",
      " [5.850943]]\n",
      "49 Cost:  0.03086486 \n",
      "Pred: \n",
      " [[5.1987753]\n",
      " [5.8509426]]\n",
      "50 Cost:  0.030863013 \n",
      "Pred: \n",
      " [[5.1987667]\n",
      " [5.8509436]]\n",
      "51 Cost:  0.030861307 \n",
      "Pred: \n",
      " [[5.1987596]\n",
      " [5.8509455]]\n",
      "52 Cost:  0.03085953 \n",
      "Pred: \n",
      " [[5.1987524]\n",
      " [5.850948 ]]\n",
      "53 Cost:  0.030857846 \n",
      "Pred: \n",
      " [[5.1987457]\n",
      " [5.8509502]]\n",
      "54 Cost:  0.030856144 \n",
      "Pred: \n",
      " [[5.19874 ]\n",
      " [5.850954]]\n",
      "55 Cost:  0.03085439 \n",
      "Pred: \n",
      " [[5.1987333]\n",
      " [5.850957 ]]\n",
      "56 Cost:  0.030852683 \n",
      "Pred: \n",
      " [[5.1987276]\n",
      " [5.8509607]]\n",
      "57 Cost:  0.030850789 \n",
      "Pred: \n",
      " [[5.198721 ]\n",
      " [5.8509645]]\n",
      "58 Cost:  0.030849082 \n",
      "Pred: \n",
      " [[5.198715 ]\n",
      " [5.8509684]]\n",
      "59 Cost:  0.030847378 \n",
      "Pred: \n",
      " [[5.1987095]\n",
      " [5.850972 ]]\n",
      "60 Cost:  0.0308456 \n",
      "Pred: \n",
      " [[5.198704 ]\n",
      " [5.8509765]]\n",
      "61 Cost:  0.030843966 \n",
      "Pred: \n",
      " [[5.198698]\n",
      " [5.85098 ]]\n",
      "62 Cost:  0.030842118 \n",
      "Pred: \n",
      " [[5.1986923]\n",
      " [5.8509846]]\n",
      "63 Cost:  0.030840412 \n",
      "Pred: \n",
      " [[5.1986866]\n",
      " [5.8509884]]\n",
      "64 Cost:  0.030838637 \n",
      "Pred: \n",
      " [[5.198681 ]\n",
      " [5.8509927]]\n",
      "65 Cost:  0.030837001 \n",
      "Pred: \n",
      " [[5.198675]\n",
      " [5.850996]]\n",
      "66 Cost:  0.030835345 \n",
      "Pred: \n",
      " [[5.1986704]\n",
      " [5.851001 ]]\n",
      "67 Cost:  0.03083364 \n",
      "Pred: \n",
      " [[5.1986647]\n",
      " [5.8510046]]\n",
      "68 Cost:  0.030831791 \n",
      "Pred: \n",
      " [[5.198659 ]\n",
      " [5.8510094]]\n",
      "69 Cost:  0.030830087 \n",
      "Pred: \n",
      " [[5.198653]\n",
      " [5.851013]]\n",
      "70 Cost:  0.030828241 \n",
      "Pred: \n",
      " [[5.1986475]\n",
      " [5.851018 ]]\n",
      "71 Cost:  0.030826628 \n",
      "Pred: \n",
      " [[5.1986423]\n",
      " [5.851022 ]]\n",
      "72 Cost:  0.030824926 \n",
      "Pred: \n",
      " [[5.1986365]\n",
      " [5.8510256]]\n",
      "73 Cost:  0.030823316 \n",
      "Pred: \n",
      " [[5.1986313]\n",
      " [5.8510294]]\n",
      "74 Cost:  0.030821467 \n",
      "Pred: \n",
      " [[5.1986256]\n",
      " [5.851034 ]]\n",
      "75 Cost:  0.030819762 \n",
      "Pred: \n",
      " [[5.19862 ]\n",
      " [5.851038]]\n",
      "76 Cost:  0.030817915 \n",
      "Pred: \n",
      " [[5.198614 ]\n",
      " [5.8510427]]\n",
      "77 Cost:  0.030816212 \n",
      "Pred: \n",
      " [[5.1986084]\n",
      " [5.8510466]]\n",
      "78 Cost:  0.030814555 \n",
      "Pred: \n",
      " [[5.1986036]\n",
      " [5.8510513]]\n",
      "79 Cost:  0.030812848 \n",
      "Pred: \n",
      " [[5.198598]\n",
      " [5.851055]]\n",
      "80 Cost:  0.030811073 \n",
      "Pred: \n",
      " [[5.198592 ]\n",
      " [5.8510594]]\n",
      "81 Cost:  0.03080944 \n",
      "Pred: \n",
      " [[5.1985865]\n",
      " [5.851063 ]]\n",
      "82 Cost:  0.030807594 \n",
      "Pred: \n",
      " [[5.1985807]\n",
      " [5.8510675]]\n",
      "83 Cost:  0.030805748 \n",
      "Pred: \n",
      " [[5.198575 ]\n",
      " [5.8510723]]\n",
      "84 Cost:  0.030804139 \n",
      "Pred: \n",
      " [[5.19857 ]\n",
      " [5.851076]]\n",
      "85 Cost:  0.03080253 \n",
      "Pred: \n",
      " [[5.1985645]\n",
      " [5.85108  ]]\n",
      "86 Cost:  0.030800682 \n",
      "Pred: \n",
      " [[5.198559 ]\n",
      " [5.8510847]]\n",
      "87 Cost:  0.03079898 \n",
      "Pred: \n",
      " [[5.198553 ]\n",
      " [5.8510885]]\n",
      "88 Cost:  0.030797273 \n",
      "Pred: \n",
      " [[5.1985474]\n",
      " [5.8510923]]\n",
      "89 Cost:  0.03079557 \n",
      "Pred: \n",
      " [[5.1985416]\n",
      " [5.851096 ]]\n",
      "90 Cost:  0.030793723 \n",
      "Pred: \n",
      " [[5.198536]\n",
      " [5.851101]]\n",
      "91 Cost:  0.030791972 \n",
      "Pred: \n",
      " [[5.1985307]\n",
      " [5.8511057]]\n",
      "92 Cost:  0.030790268 \n",
      "Pred: \n",
      " [[5.198525 ]\n",
      " [5.8511095]]\n",
      "93 Cost:  0.030788658 \n",
      "Pred: \n",
      " [[5.1985197]\n",
      " [5.8511133]]\n",
      "94 Cost:  0.030786812 \n",
      "Pred: \n",
      " [[5.198514]\n",
      " [5.851118]]\n",
      "95 Cost:  0.03078511 \n",
      "Pred: \n",
      " [[5.1985083]\n",
      " [5.851122 ]]\n",
      "96 Cost:  0.030783335 \n",
      "Pred: \n",
      " [[5.1985025]\n",
      " [5.851126 ]]\n",
      "97 Cost:  0.03078156 \n",
      "Pred: \n",
      " [[5.198497 ]\n",
      " [5.8511305]]\n",
      "98 Cost:  0.030779975 \n",
      "Pred: \n",
      " [[5.198492]\n",
      " [5.851135]]\n",
      "99 Cost:  0.0307782 \n",
      "Pred: \n",
      " [[5.1984863]\n",
      " [5.851139 ]]\n",
      "100 Cost:  0.030776497 \n",
      "Pred: \n",
      " [[5.1984806]\n",
      " [5.851143 ]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, :-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "'''\n",
    "xy = array([[ 1,  2, 30,  4,  5],\n",
    "           [2, 3, 40, 5, 6]])\n",
    "    '''\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 1e-4).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(101):\n",
    "        _, cost_val, hy_val = sess.run(\n",
    "                [train, cost, hypothesis], feed_dict = {X: x_data, Y: y_data})\n",
    "        \n",
    "        print(step, 'Cost: ', cost_val, '\\nPred: \\n', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1984806],\n",
       "       [5.851143 ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2, 30,  4,  5],\n",
       "       [ 2,  3, 40,  5,  6]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2, 30,  4]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy[:1, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([198.19492], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xy[:1, :-1] * hy_val[0]) + hy_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([458.11896], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xy[:2, :-1] * hy_val[0]) + hy_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.35"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xy[:2, :-1] * 1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8499999999999999"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xy[:1, :-1] * 1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.5 , 7.5 , 1.  ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy[:1, :-1] * 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.04340171813965"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xy[:1, :-1] * hy_val[0]) + 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 30,  4,  5])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(xy, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0],\n",
       "       [ 1,  1, 10,  1,  1]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy - np.min(xy, 0) # xy - [[ 1,  2, 30,  4,  5],\n",
    "                    #      [ 1,  2, 30,  4,  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3, 40,  5,  6])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(xy, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 10,  1,  1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(xy, 0) - np.min(xy, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0]\n",
      " [ 1  1 10  1  1]] [ 1  1 10  1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.9999999 , 0.9999999 , 0.99999999, 0.9999999 , 0.9999999 ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xy - np.min(xy, 0)) / (np.max(xy, 0) - np.min(xy, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.9999999 , 0.9999999 , 0.99999999, 0.9999999 , 0.9999999 ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xy - np.min(xy, 0)) / (np.max(xy, 0) - np.min(xy, 0) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = (xy - np.min(xy, 0)) / (np.max(xy, 0) - np.min(xy, 0) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       ],\n",
       "       [0.9999999]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  3.445763 \n",
      "Pred: \n",
      " [[ 0.24895923]\n",
      " [-1.6133399 ]]\n",
      "1 Cost:  3.125172 \n",
      "Pred: \n",
      " [[ 0.27260303]\n",
      " [-1.4851625 ]]\n",
      "2 Cost:  2.8368065 \n",
      "Pred: \n",
      " [[ 0.29472864]\n",
      " [-1.3636304 ]]\n",
      "3 Cost:  2.5773869 \n",
      "Pred: \n",
      " [[ 0.31541765]\n",
      " [-1.2483963 ]]\n",
      "4 Cost:  2.3439677 \n",
      "Pred: \n",
      " [[ 0.33474743]\n",
      " [-1.1391306 ]]\n",
      "5 Cost:  2.1339047 \n",
      "Pred: \n",
      " [[ 0.35279125]\n",
      " [-1.0355215 ]]\n",
      "6 Cost:  1.9448228 \n",
      "Pred: \n",
      " [[ 0.36961856]\n",
      " [-0.9372734 ]]\n",
      "7 Cost:  1.7745893 \n",
      "Pred: \n",
      " [[ 0.38529512]\n",
      " [-0.84410596]]\n",
      "8 Cost:  1.6212883 \n",
      "Pred: \n",
      " [[ 0.39988324]\n",
      " [-0.7557535 ]]\n",
      "9 Cost:  1.4832 \n",
      "Pred: \n",
      " [[ 0.41344196]\n",
      " [-0.6719648 ]]\n",
      "10 Cost:  1.3587792 \n",
      "Pred: \n",
      " [[ 0.42602718]\n",
      " [-0.59250104]]\n",
      "11 Cost:  1.2466381 \n",
      "Pred: \n",
      " [[ 0.43769193]\n",
      " [-0.51713616]]\n",
      "12 Cost:  1.1455308 \n",
      "Pred: \n",
      " [[ 0.44848636]\n",
      " [-0.44565627]]\n",
      "13 Cost:  1.0543386 \n",
      "Pred: \n",
      " [[ 0.45845807]\n",
      " [-0.3778584 ]]\n",
      "14 Cost:  0.97205603 \n",
      "Pred: \n",
      " [[ 0.46765208]\n",
      " [-0.3135501 ]]\n",
      "15 Cost:  0.8977803 \n",
      "Pred: \n",
      " [[ 0.47611105]\n",
      " [-0.25254905]]\n",
      "16 Cost:  0.8307011 \n",
      "Pred: \n",
      " [[ 0.48387542]\n",
      " [-0.1946828 ]]\n",
      "17 Cost:  0.77009 \n",
      "Pred: \n",
      " [[ 0.4909835 ]\n",
      " [-0.13978744]]\n",
      "18 Cost:  0.71529305 \n",
      "Pred: \n",
      " [[ 0.4974715 ]\n",
      " [-0.08770794]]\n",
      "19 Cost:  0.66572297 \n",
      "Pred: \n",
      " [[ 0.50337386]\n",
      " [-0.03829718]]\n",
      "20 Cost:  0.6208524 \n",
      "Pred: \n",
      " [[0.5087231]\n",
      " [0.0085839]]\n",
      "21 Cost:  0.58020735 \n",
      "Pred: \n",
      " [[0.51355   ]\n",
      " [0.05306739]]\n",
      "22 Cost:  0.54336226 \n",
      "Pred: \n",
      " [[0.51788384]\n",
      " [0.09527844]]\n",
      "23 Cost:  0.50993466 \n",
      "Pred: \n",
      " [[0.52175224]\n",
      " [0.1353358 ]]\n",
      "24 Cost:  0.4795816 \n",
      "Pred: \n",
      " [[0.52518135]\n",
      " [0.17335144]]\n",
      "25 Cost:  0.4519943 \n",
      "Pred: \n",
      " [[0.52819604]\n",
      " [0.209432  ]]\n",
      "26 Cost:  0.42689577 \n",
      "Pred: \n",
      " [[0.5308198 ]\n",
      " [0.24367854]]\n",
      "27 Cost:  0.4040373 \n",
      "Pred: \n",
      " [[0.5330748 ]\n",
      " [0.27618647]]\n",
      "28 Cost:  0.38319522 \n",
      "Pred: \n",
      " [[0.5349822 ]\n",
      " [0.30704644]]\n",
      "29 Cost:  0.36416876 \n",
      "Pred: \n",
      " [[0.5365619 ]\n",
      " [0.33634424]]\n",
      "30 Cost:  0.34677744 \n",
      "Pred: \n",
      " [[0.53783286]\n",
      " [0.3641613 ]]\n",
      "31 Cost:  0.33085907 \n",
      "Pred: \n",
      " [[0.53881294]\n",
      " [0.39057493]]\n",
      "32 Cost:  0.31626815 \n",
      "Pred: \n",
      " [[0.5395191]\n",
      " [0.415658 ]]\n",
      "33 Cost:  0.3028737 \n",
      "Pred: \n",
      " [[0.5399673 ]\n",
      " [0.43947986]]\n",
      "34 Cost:  0.29055813 \n",
      "Pred: \n",
      " [[0.5401728]\n",
      " [0.4621062]]\n",
      "35 Cost:  0.27921587 \n",
      "Pred: \n",
      " [[0.54015005]\n",
      " [0.48359922]]\n",
      "36 Cost:  0.2687519 \n",
      "Pred: \n",
      " [[0.5399126 ]\n",
      " [0.50401783]]\n",
      "37 Cost:  0.25908095 \n",
      "Pred: \n",
      " [[0.5394733 ]\n",
      " [0.52341783]]\n",
      "38 Cost:  0.25012627 \n",
      "Pred: \n",
      " [[0.5388444 ]\n",
      " [0.54185224]]\n",
      "39 Cost:  0.241819 \n",
      "Pred: \n",
      " [[0.5380374]\n",
      " [0.5593711]]\n",
      "40 Cost:  0.23409703 \n",
      "Pred: \n",
      " [[0.53706336]\n",
      " [0.57602227]]\n",
      "41 Cost:  0.22690478 \n",
      "Pred: \n",
      " [[0.5359325]\n",
      " [0.5918505]]\n",
      "42 Cost:  0.22019209 \n",
      "Pred: \n",
      " [[0.5346547 ]\n",
      " [0.60689867]]\n",
      "43 Cost:  0.21391392 \n",
      "Pred: \n",
      " [[0.5332391 ]\n",
      " [0.62120724]]\n",
      "44 Cost:  0.20802982 \n",
      "Pred: \n",
      " [[0.53169465]\n",
      " [0.6348144 ]]\n",
      "45 Cost:  0.20250328 \n",
      "Pred: \n",
      " [[0.53002954]\n",
      " [0.6477567 ]]\n",
      "46 Cost:  0.19730157 \n",
      "Pred: \n",
      " [[0.52825165]\n",
      " [0.6600685 ]]\n",
      "47 Cost:  0.19239515 \n",
      "Pred: \n",
      " [[0.52636844]\n",
      " [0.6717826 ]]\n",
      "48 Cost:  0.18775754 \n",
      "Pred: \n",
      " [[0.52438694]\n",
      " [0.6829299 ]]\n",
      "49 Cost:  0.18336482 \n",
      "Pred: \n",
      " [[0.5223138]\n",
      " [0.6935395]]\n",
      "50 Cost:  0.17919548 \n",
      "Pred: \n",
      " [[0.52015525]\n",
      " [0.7036395 ]]\n",
      "51 Cost:  0.17523018 \n",
      "Pred: \n",
      " [[0.5179173]\n",
      " [0.713256 ]]\n",
      "52 Cost:  0.17145148 \n",
      "Pred: \n",
      " [[0.51560557]\n",
      " [0.72241414]]\n",
      "53 Cost:  0.16784367 \n",
      "Pred: \n",
      " [[0.5132254]\n",
      " [0.7311374]]\n",
      "54 Cost:  0.16439258 \n",
      "Pred: \n",
      " [[0.51078176]\n",
      " [0.7394483 ]]\n",
      "55 Cost:  0.1610854 \n",
      "Pred: \n",
      " [[0.50827944]\n",
      " [0.7473681 ]]\n",
      "56 Cost:  0.15791067 \n",
      "Pred: \n",
      " [[0.50572294]\n",
      " [0.7549169 ]]\n",
      "57 Cost:  0.15485802 \n",
      "Pred: \n",
      " [[0.50311655]\n",
      " [0.7621138 ]]\n",
      "58 Cost:  0.15191804 \n",
      "Pred: \n",
      " [[0.50046426]\n",
      " [0.7689769 ]]\n",
      "59 Cost:  0.14908224 \n",
      "Pred: \n",
      " [[0.49776983]\n",
      " [0.7755234 ]]\n",
      "60 Cost:  0.14634301 \n",
      "Pred: \n",
      " [[0.4950369]\n",
      " [0.7817695]]\n",
      "61 Cost:  0.14369343 \n",
      "Pred: \n",
      " [[0.49226883]\n",
      " [0.7877306 ]]\n",
      "62 Cost:  0.14112723 \n",
      "Pred: \n",
      " [[0.48946884]\n",
      " [0.7934213 ]]\n",
      "63 Cost:  0.13863873 \n",
      "Pred: \n",
      " [[0.48663995]\n",
      " [0.79885554]]\n",
      "64 Cost:  0.13622287 \n",
      "Pred: \n",
      " [[0.483785  ]\n",
      " [0.80404633]]\n",
      "65 Cost:  0.13387492 \n",
      "Pred: \n",
      " [[0.4809067]\n",
      " [0.8090062]]\n",
      "66 Cost:  0.13159071 \n",
      "Pred: \n",
      " [[0.47800756]\n",
      " [0.8137468 ]]\n",
      "67 Cost:  0.12936643 \n",
      "Pred: \n",
      " [[0.47509  ]\n",
      " [0.8182794]]\n",
      "68 Cost:  0.12719858 \n",
      "Pred: \n",
      " [[0.47215632]\n",
      " [0.82261455]]\n",
      "69 Cost:  0.125084 \n",
      "Pred: \n",
      " [[0.4692086]\n",
      " [0.8267622]]\n",
      "70 Cost:  0.12301983 \n",
      "Pred: \n",
      " [[0.4662489]\n",
      " [0.830732 ]]\n",
      "71 Cost:  0.12100343 \n",
      "Pred: \n",
      " [[0.4632791 ]\n",
      " [0.83453286]]\n",
      "72 Cost:  0.1190324 \n",
      "Pred: \n",
      " [[0.46030098]\n",
      " [0.8381734 ]]\n",
      "73 Cost:  0.11710457 \n",
      "Pred: \n",
      " [[0.45731625]\n",
      " [0.8416617 ]]\n",
      "74 Cost:  0.115217924 \n",
      "Pred: \n",
      " [[0.45432648]\n",
      " [0.8450054 ]]\n",
      "75 Cost:  0.113370605 \n",
      "Pred: \n",
      " [[0.45133317]\n",
      " [0.84821194]]\n",
      "76 Cost:  0.11156095 \n",
      "Pred: \n",
      " [[0.4483377]\n",
      " [0.8512881]]\n",
      "77 Cost:  0.10978743 \n",
      "Pred: \n",
      " [[0.44534144]\n",
      " [0.8542403 ]]\n",
      "78 Cost:  0.10804862 \n",
      "Pred: \n",
      " [[0.44234562]\n",
      " [0.8570748 ]]\n",
      "79 Cost:  0.106343165 \n",
      "Pred: \n",
      " [[0.4393514]\n",
      " [0.8597976]]\n",
      "80 Cost:  0.104669906 \n",
      "Pred: \n",
      " [[0.4363599]\n",
      " [0.8624141]]\n",
      "81 Cost:  0.103027664 \n",
      "Pred: \n",
      " [[0.43337217]\n",
      " [0.8649299 ]]\n",
      "82 Cost:  0.101415455 \n",
      "Pred: \n",
      " [[0.43038914]\n",
      " [0.8673496 ]]\n",
      "83 Cost:  0.09983225 \n",
      "Pred: \n",
      " [[0.42741174]\n",
      " [0.86967826]]\n",
      "84 Cost:  0.09827721 \n",
      "Pred: \n",
      " [[0.42444083]\n",
      " [0.87192017]]\n",
      "85 Cost:  0.09674948 \n",
      "Pred: \n",
      " [[0.42147723]\n",
      " [0.8740797 ]]\n",
      "86 Cost:  0.09524824 \n",
      "Pred: \n",
      " [[0.41852167]\n",
      " [0.876161  ]]\n",
      "87 Cost:  0.09377277 \n",
      "Pred: \n",
      " [[0.41557485]\n",
      " [0.8781677 ]]\n",
      "88 Cost:  0.09232239 \n",
      "Pred: \n",
      " [[0.4126374]\n",
      " [0.8801035]]\n",
      "89 Cost:  0.090896435 \n",
      "Pred: \n",
      " [[0.40971   ]\n",
      " [0.88197196]]\n",
      "90 Cost:  0.0894943 \n",
      "Pred: \n",
      " [[0.40679318]\n",
      " [0.8837763 ]]\n",
      "91 Cost:  0.08811542 \n",
      "Pred: \n",
      " [[0.40388748]\n",
      " [0.8855196 ]]\n",
      "92 Cost:  0.086759225 \n",
      "Pred: \n",
      " [[0.4009934 ]\n",
      " [0.88720477]]\n",
      "93 Cost:  0.08542522 \n",
      "Pred: \n",
      " [[0.39811143]\n",
      " [0.8888346 ]]\n",
      "94 Cost:  0.08411289 \n",
      "Pred: \n",
      " [[0.39524198]\n",
      " [0.89041173]]\n",
      "95 Cost:  0.08282177 \n",
      "Pred: \n",
      " [[0.39238542]\n",
      " [0.8919387 ]]\n",
      "96 Cost:  0.08155141 \n",
      "Pred: \n",
      " [[0.3895422 ]\n",
      " [0.89341795]]\n",
      "97 Cost:  0.0803014 \n",
      "Pred: \n",
      " [[0.38671258]\n",
      " [0.89485157]]\n",
      "98 Cost:  0.07907129 \n",
      "Pred: \n",
      " [[0.38389695]\n",
      " [0.8962419 ]]\n",
      "99 Cost:  0.07786071 \n",
      "Pred: \n",
      " [[0.38109556]\n",
      " [0.8975909 ]]\n",
      "100 Cost:  0.07666929 \n",
      "Pred: \n",
      " [[0.37830868]\n",
      " [0.8989003 ]]\n"
     ]
    }
   ],
   "source": [
    "x_data = XX[:, :-1]\n",
    "y_data = XX[:, [-1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "'''\n",
    "XX = array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "       [0.9999999 , 0.9999999 , 0.99999999, 0.9999999 , 0.9999999]])\n",
    "    '''\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 1e-2).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(101):\n",
    "        _, cost_val, hy_val = sess.run(\n",
    "                [train, cost, hypothesis], feed_dict = {X: x_data, Y: y_data})\n",
    "        \n",
    "        print(step, 'Cost: ', cost_val, '\\nPred: \\n', hy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
